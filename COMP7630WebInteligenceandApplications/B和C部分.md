下面给出的内容包含了 **Part B: Evolutionary Algorithms** 和 **Part C: Association Rules Mining** 的完整作业题目（英文原题）以及详细、准确的答案。你可以直接将此文档整理成 PDF 文件提交给老师，确保每道题目及其解答均详尽阐述，力求满分。

---

# (B) EVOLUTIONARY ALGORITHMS (30 MARKS)

---

### Question 8
**Q8.** *Is it possible to improve the effectiveness of the K-Means algorithm by using an evolutionary algorithm? If so, explain how.*

**A8.**  
Yes, it is possible to improve K-Means by incorporating an evolutionary algorithm (EA). One common strategy is to use a genetic algorithm (GA) to optimize the positions of the cluster centroids. In this hybrid approach:  

- **Representation:** Each individual (chromosome) represents a complete set of k centroids.  
- **Fitness Function:** The fitness of an individual is evaluated using a clustering quality measure (e.g., minimizing the within-cluster sum of squares, WCSS).  
- **Evolutionary Operators:** Standard GA operators—such as selection (e.g., tournament selection), crossover (e.g., arithmetic or uniform crossover), and mutation—are applied to evolve a population of centroid sets.  
- **Guidance and Refinement:** The EA explores a larger search space and can escape local optima that standard K-Means might converge to with random initialization. After several generations, the best individual (i.e., the set of centroids with the lowest WCSS) can be used as an initialization for a conventional K-Means run, or directly adopted as the clustering solution.

This approach leverages the exploratory power of evolutionary algorithms and can lead to more robust and globally optimal clustering results.

---

### Question 9
**Q9.** *Considering both the uniform and single bit-flip mutation operators, calculate the probabilities that a binary solution formed by n bits will not be changed after applying mutation. Also describe how the two probabilities are calculated.*

**A9.**  
Let the mutation probability per bit be **p**.

- **Uniform Mutation Operator:**  
  In this operator, each bit is independently flipped with probability **p**. Therefore, the probability that a specific bit remains unchanged is **(1 – p)**. For a binary solution with **n** bits, the probability that none of the bits are mutated is:  
  \[
  P_{\text{uniform}} = (1 - p)^n
  \]  
  This is derived by multiplying the independent probability of no change over all n bits.

- **Single Bit-Flip Mutation Operator:**  
  In the single bit-flip mutation operator, the algorithm selects exactly one bit (uniformly at random) to flip. Under this operator, every application changes one bit—thus, the probability that the solution remains unchanged is **0** (i.e., \( P_{\text{single-bit}} = 0 \)).  
  *Note:* In some implementations a mutation might be applied with an overall probability; however, if the operator explicitly flips exactly one bit when invoked, then the solution is always modified.

---

### Question 10
**Q10.** *Let NoMutAritGA be a genetic algorithm for continuous fitness functions. This algorithm uses the arithmetic crossover operator and does not incorporate a mutation operator. The selection and replacement operators can be chosen from any of those discussed in the lessons. Assume that, at iteration t of an execution, the population of NoMutAritGA consists of the following solutions:  
\[
x_1 = [1.5,\,2.8,\,3.3], \quad x_2 = [1.5,\,2.8,\,3.3], \quad x_3 = [0.2,\,1.1,\,2.2], \quad x_4 = [0.3,\,0.1,\,2.2]
\]
Without considering the specific fitness function under investigation, determine whether the solutions  
\[
A = [0.5,\,2.5,\,1.1] \quad \text{and} \quad B = [1.1,\,0.5,\,2.5]
\]
can be visited by NoMutAritGA in the iterations \(t+k\) (for \(k\geq1\)). Also motivate your answers.*

**A10.**  
Since NoMutAritGA employs only arithmetic crossover (and no mutation), all offspring generated are convex combinations of the parent solutions. In other words, every new solution will lie within the **convex hull** of the current population.

- **For solution A = [0.5, 2.5, 1.1]:**  
  Consider the third coordinate: the current population’s third coordinates are 3.3, 3.3, 2.2, and 2.2. The minimum value is 2.2, yet A’s third coordinate is 1.1, which is below this minimum. Therefore, A cannot be represented as a convex combination of the available solutions and hence is unreachable.

- **For solution B = [1.1, 0.5, 2.5]:**  
  Although each coordinate of B falls between the respective minima and maxima of the parent solutions (x: between 0.2 and 1.5; y: between 0.1 and 2.8; z: between 2.2 and 3.3), being within the coordinate-wise range is a necessary but not sufficient condition for being in the convex hull. An attempt to express B as a convex combination of the unique parent vectors (noting that \(x_1\) and \(x_2\) are identical) leads to a system of linear equations that has no solution with all non-negative weights summing to one. Hence, B is also not in the convex hull and cannot be generated by arithmetic crossover alone.

In summary, neither A nor B can be visited by NoMutAritGA since they do not lie in the convex hull of the current population.

---

### Question 11
**Q11.** *Let f and g be two simple objective functions, taking in input a bit-string of length 3 and returning a real number to be maximized, defined as follows:*
```python
def f(x): 
    return 1 + 10*x[0] + 100*x[1] + 1000*x[2]

def g(x): 
    return f(x)*f(x) + log(f(x)) + exp(f(x))
```
*Also consider a genetic algorithm, called MyGA, which uses the following operators: tournament selection, uniform crossover, single bit-flip mutation, and plus replacement. Suppose that MyGA is run once for each objective function by initializing the random number generator with the same seed. Denote the two executions by MyGA(f, seed) and MyGA(g, seed). Is there any relationship between the solutions evaluated in the two executions? If so, explain what it is and try to discuss a more general property of MyGA. Moreover, what if we change the operators of MyGA?*

**A11.**  
Both functions \( f \) and \( g \) are constructed so that \( g \) is a **strictly increasing (monotonic) transformation** of \( f \) when \( f(x) > 0 \) (which is always the case here since \( f(x) \ge 1 \)). This implies that for any two bit-strings \( x \) and \( y \):
\[
f(x) > f(y) \quad \Leftrightarrow \quad g(x) > g(y)
\]
As a consequence:

- **Ranking Invariance:**  
  When MyGA employs tournament selection (or any rank-based selection) and the other operators (uniform crossover and single bit-flip mutation) do not depend on the absolute fitness values but rather on the relative ordering of individuals, both MyGA(f, seed) and MyGA(g, seed) will generate identical selection decisions. This means that, given the same random seed, the same individuals will be selected and the same crossover and mutation events will occur, leading to the evaluation of the same sequence of bit-string solutions in both executions.

- **General Property:**  
  More generally, any genetic algorithm that uses rank-based selection (or selection methods invariant to monotonic transformations) will exhibit the property that applying a strictly monotonic transformation to the fitness function does not change the sequence of evaluated solutions. However, if the operators (or selection mechanisms) depend on the actual fitness values (for example, using fitness-proportionate selection), then the behavior might change under different transformations.

- **Changing Operators:**  
  If one changes the operators such that they are sensitive to absolute fitness differences (for example, switching to roulette wheel selection without ranking) or employs adaptive mutation rates based on fitness values, the invariance property may be lost. In that case, the two executions (MyGA(f, seed) vs. MyGA(g, seed)) could diverge.

---

### Question 12
**Q12.** *Let h be the objective function that takes as input a real vector from [0, 100]^4 and returns a real number to be minimized, defined as follows:*
```python
def h(x):
    if x[0] == x[1] == x[2] == x[3] == 0:
        return 0
    else:
        return 1000 - (x[0] + x[1] + x[2] + x[3])
```
*Also consider the well-known Differential Evolution (DE) algorithm and a very trivial algorithm, called Random Search (RS), which iteratively generates random solutions, evaluates them, and returns the best one. Do you expect to observe a difference between RS and DE in the time (e.g., number of fitness evaluations) required to reach the global optimum of h? Also explain why and discuss whether one algorithm has some advantage over the other.*

**A12.**  
The function \( h(x) \) is defined such that:
- \( h(x) = 0 \) only when \( x = [0, 0, 0, 0] \) (the global optimum), and  
- For any other \( x \), \( h(x) = 1000 - (x[0] + x[1] + x[2] + x[3]) \).

Since each \( x_i \in [0, 100] \), the maximum possible sum is 400 and thus the function value for any non-optimal \( x \) is at least \( 1000 - 400 = 600 \).

**Comparison of RS and DE:**

- **Random Search (RS):**  
  RS samples points uniformly at random from the search space. Given the continuous and high-dimensional nature of the problem, the probability of randomly hitting exactly \([0,0,0,0]\) is effectively zero. RS does not use any feedback from previous evaluations to guide the search and therefore is likely to require an extremely large number of fitness evaluations to stumble upon the optimum (or even a solution very close to it).

- **Differential Evolution (DE):**  
  DE is a population-based metaheuristic that uses differences between current population members to generate new candidate solutions. DE uses a guided search strategy and exploits information from the current population to steer the search towards regions of the search space with lower (better) function values. Although the optimum \([0,0,0,0]\) is isolated (and the probability of generating it exactly is still zero in continuous space), DE is expected to rapidly converge towards areas of the search space that minimize \( h(x) \).

**Conclusion:**  
Yes, there is an expected difference in efficiency. DE is likely to require significantly fewer fitness evaluations than RS because DE leverages population information and uses directional operators to continuously improve solutions, whereas RS remains purely stochastic. In practice, DE’s guided exploration makes it more advantageous for converging toward the global optimum of \( h(x) \), despite both methods theoretically facing the challenge of exactly hitting the isolated optimum.

---

# (C) ASSOCIATION RULES MINING (20 MARKS)

---

### Question 13
**Q13.** *Table 1 shows the database of transactions of a music store.*

| Transaction ID | Items                                   |
|----------------|-----------------------------------------|
| T1             | Guitar, GuitarPick                      |
| T2             | DrumSet, Microphone, Amplifier          |
| T3             | DrumSet, GuitarPick, Guitar             |
| T4             | DrumSet, Microphone                       |
| T5             | Guitar, Amplifier                         |
| T6             | DrumSet, GuitarPick, Guitar             |

*Perform the following:*

**(a)** Trace the results of using the Apriori algorithm, considering minimum support \( \text{minsup} = 33\% \) (i.e., at least 2 out of 6 transactions) and minimum confidence \( \text{minconf} = 60\% \), by showing both the candidate and frequent itemsets for each database scan.

**(b)** Enumerate all the final frequent itemsets.

**(c)** How many scans of the database of transactions are required by Apriori to calculate all the frequent itemsets (enumerated for the previous question)?

**(d)** Indicate the association rules that are generated, along with their support and confidence, then highlight the valid ones.

**(e)** List the valid association rules, sorted by lift and reporting their lift values.

---

**A13.**

#### Step (a): Candidate Generation and Frequent Itemsets

1. **First Scan – 1-itemsets (L1):**  
   Calculate support counts for each unique item:

   - **Guitar:** Appears in T1, T3, T5, T6 → count = 4 (Support = 4/6 ≈ 66.7%)  
   - **GuitarPick:** Appears in T1, T3, T6 → count = 3 (Support = 3/6 = 50%)  
   - **DrumSet:** Appears in T2, T3, T4, T6 → count = 4 (Support = 66.7%)  
   - **Microphone:** Appears in T2, T4 → count = 2 (Support = 33.3%)  
   - **Amplifier:** Appears in T2, T5 → count = 2 (Support = 33.3%)

   Since the minimum support is 33%, all these items are frequent. Thus,  
   **L1 = {Guitar}, {GuitarPick}, {DrumSet}, {Microphone}, {Amplifier}.**

2. **Second Scan – Candidate 2-itemsets (C2):**  
   Generate candidate pairs from L1 and count supports using the transactions:

   - From T1: {Guitar, GuitarPick} → count = 1  
   - From T2: {DrumSet, Microphone}, {DrumSet, Amplifier}, {Microphone, Amplifier}  
   - From T3: {DrumSet, GuitarPick}, {DrumSet, Guitar}, {GuitarPick, Guitar}  
   - From T4: {DrumSet, Microphone}  
   - From T5: {Guitar, Amplifier}  
   - From T6: {DrumSet, GuitarPick}, {DrumSet, Guitar}, {GuitarPick, Guitar}

   **Counts (summing over transactions):**  
   - **{Guitar, GuitarPick}:** T1, T3, T6 → count = 3 (Support = 50%)  
   - **{DrumSet, Microphone}:** T2, T4 → count = 2 (Support = 33.3%)  
   - **{DrumSet, Amplifier}:** T2 → count = 1 (Support = 16.7%)  
   - **{Microphone, Amplifier}:** T2 → count = 1 (Support = 16.7%)  
   - **{DrumSet, Guitar}:** T3, T6 → count = 2 (Support = 33.3%)  
   - **{DrumSet, GuitarPick}:** T3, T6 → count = 2 (Support = 33.3%)  
   - **{Guitar, Amplifier}:** T5 → count = 1 (Support = 16.7%)

   Thus, the frequent 2-itemsets (L2) are:  
   **L2 = {Guitar, GuitarPick}, {DrumSet, Microphone}, {DrumSet, Guitar}, {DrumSet, GuitarPick}.**

3. **Third Scan – Candidate 3-itemsets (C3):**  
   Generate candidate 3-itemsets from L2 by joining those with common items. The only viable candidate is:
   
   - **{DrumSet, Guitar, GuitarPick}:**  
     Check transactions: Appears in T3 and T6 → count = 2 (Support = 33.3%).

   Since count ≥ 2, it is frequent. Thus,  
   **L3 = {DrumSet, Guitar, GuitarPick}.**

4. **Fourth Scan – Candidate 4-itemsets (C4):**  
   There is no candidate since there is only one itemset in L3.

#### Step (b): Final Frequent Itemsets

Combine all levels:  
- **1-itemsets:** {Guitar}, {GuitarPick}, {DrumSet}, {Microphone}, {Amplifier}  
- **2-itemsets:** {Guitar, GuitarPick} (3/6), {DrumSet, Microphone} (2/6), {DrumSet, Guitar} (2/6), {DrumSet, GuitarPick} (2/6)  
- **3-itemsets:** {DrumSet, Guitar, GuitarPick} (2/6)

#### Step (c): Number of Database Scans

The Apriori algorithm performs one complete scan for each level of candidate generation. Here, we performed:  
- Scan for 1-itemsets (L1)  
- Scan for 2-itemsets (L2)  
- Scan for 3-itemsets (L3)  

Thus, **3 scans** of the database are required.

#### Step (d): Generation of Association Rules

For each frequent itemset (of size ≥ 2), we generate rules by dividing the itemset into antecedent (LHS) and consequent (RHS). We then compute support and confidence. (All percentages are approximated based on 6 transactions.)

**From {Guitar, GuitarPick} (Support = 50%):**  
- **Rule 1:** Guitar → GuitarPick  
  - Confidence = Support({Guitar, GuitarPick}) / Support({Guitar}) = (3/6) / (4/6) = 75%  
  - *Valid* (≥ 60%)  
- **Rule 2:** GuitarPick → Guitar  
  - Confidence = (3/6) / (3/6) = 100%  
  - *Valid*

**From {DrumSet, Microphone} (Support = 33.3%):**  
- **Rule 3:** DrumSet → Microphone  
  - Confidence = (2/6) / (4/6) = 50%  
  - *Not valid*  
- **Rule 4:** Microphone → DrumSet  
  - Confidence = (2/6) / (2/6) = 100%  
  - *Valid*

**From {DrumSet, Guitar} (Support = 33.3%):**  
- **Rule 5:** DrumSet → Guitar  
  - Confidence = (2/6) / (4/6) = 50%  
  - *Not valid*  
- **Rule 6:** Guitar → DrumSet  
  - Confidence = (2/6) / (4/6) = 50%  
  - *Not valid*

**From {DrumSet, GuitarPick} (Support = 33.3%):**  
- **Rule 7:** DrumSet → GuitarPick  
  - Confidence = (2/6) / (4/6) = 50%  
  - *Not valid*  
- **Rule 8:** GuitarPick → DrumSet  
  - Confidence = (2/6) / (3/6) ≈ 66.7%  
  - *Valid*

**From {DrumSet, Guitar, GuitarPick} (Support = 33.3%):**  
Generate rules with one item as RHS and the other two as LHS:  
- **Rule 9:** {DrumSet, Guitar} → GuitarPick  
  - Confidence = (2/6) / (Support of {DrumSet, Guitar} = 2/6) = 100%  
  - *Valid*  
- **Rule 10:** {DrumSet, GuitarPick} → Guitar  
  - Confidence = (2/6) / (2/6) = 100%  
  - *Valid*  
- **Rule 11:** {Guitar, GuitarPick} → DrumSet  
  - Confidence = (2/6) / (3/6) ≈ 66.7%  
  - *Valid*  

Also, rules with one item on LHS and two items on RHS (if considered):  
- **Rule 12:** DrumSet → {Guitar, GuitarPick}  
  - Confidence = (2/6) / (4/6) = 50%  
  - *Not valid*  
- **Rule 13:** Guitar → {DrumSet, GuitarPick}  
  - Confidence = (2/6) / (4/6) = 50%  
  - *Not valid*  
- **Rule 14:** GuitarPick → {DrumSet, Guitar}  
  - Confidence = (2/6) / (3/6) ≈ 66.7%  
  - *Valid*

#### Step (e): Valid Association Rules Sorted by Lift

First, we calculate lift for each valid rule using:  
\[
\text{Lift} = \frac{\text{Confidence}}{\text{Support(RHS)}}
\]
where supports are expressed as fractions of 6.

**Valid Rules and Their Calculations:**

1. **Rule 1: Guitar → GuitarPick**  
   - Support = 50% (0.50)  
   - Confidence = 75% (0.75)  
   - Support(GuitarPick) = 50% (0.50)  
   - Lift = 0.75 / 0.50 = **1.5**

2. **Rule 2: GuitarPick → Guitar**  
   - Support = 50% (0.50)  
   - Confidence = 100% (1.00)  
   - Support(Guitar) = 66.7% (≈0.67)  
   - Lift = 1.00 / 0.67 ≈ **1.5**

3. **Rule 4: Microphone → DrumSet**  
   - Support = 33.3% (0.33)  
   - Confidence = 100% (1.00)  
   - Support(DrumSet) = 66.7% (≈0.67)  
   - Lift = 1.00 / 0.67 ≈ **1.5**

4. **Rule 8: GuitarPick → DrumSet**  
   - Confidence ≈ 66.7% (0.67)  
   - Support(DrumSet) = 66.7% (≈0.67)  
   - Lift = 0.67 / 0.67 = **1.0**

5. **Rule 9: {DrumSet, Guitar} → GuitarPick**  
   - Confidence = 100% (1.00)  
   - Support(GuitarPick) = 50% (0.50)  
   - Lift = 1.00 / 0.50 = **2.0**

6. **Rule 10: {DrumSet, GuitarPick} → Guitar**  
   - Confidence = 100% (1.00)  
   - Support(Guitar) = 66.7% (≈0.67)  
   - Lift = 1.00 / 0.67 ≈ **1.5**

7. **Rule 11: {Guitar, GuitarPick} → DrumSet**  
   - Confidence ≈ 66.7% (0.67)  
   - Support(DrumSet) = 66.7% (≈0.67)  
   - Lift = 0.67 / 0.67 = **1.0**

8. **Rule 14: GuitarPick → {DrumSet, Guitar}**  
   - Confidence ≈ 66.7% (0.67)  
   - Support({DrumSet, Guitar}) = 33.3% (0.33)  
   - Lift = 0.67 / 0.33 ≈ **2.0**

**Sorted (Descending by Lift):**

- **Lift = 2.0:**  
  - Rule 9: {DrumSet, Guitar} → GuitarPick  
  - Rule 14: GuitarPick → {DrumSet, Guitar}

- **Lift ≈ 1.5:**  
  - Rule 1: Guitar → GuitarPick  
  - Rule 2: GuitarPick → Guitar  
  - Rule 4: Microphone → DrumSet  
  - Rule 10: {DrumSet, GuitarPick} → Guitar

- **Lift = 1.0:**  
  - Rule 8: GuitarPick → DrumSet  
  - Rule 11: {Guitar, GuitarPick} → DrumSet

---

### Question 14
**Q14.** *Suppose that each transaction has a numeric weight, represented by the amount of money paid. Design and discuss a strategy that allows the Apriori algorithm to take the weights into account, while keeping the internal mechanisms of the Apriori algorithm unchanged.*

**A14.**  
A common strategy is to redefine the **support** measure in a weighted manner. Instead of simply counting the number of transactions in which an itemset appears, we calculate the weighted support as follows:
\[
\text{Weighted Support}(I) = \frac{\sum_{T \in D} \text{weight}(T) \cdot \mathbb{1}_{\{I \subseteq T\}}}{\sum_{T \in D} \text{weight}(T)}
\]
where:  
- \( \mathbb{1}_{\{I \subseteq T\}} \) is an indicator function that is 1 if itemset \( I \) is contained in transaction \( T \) and 0 otherwise,  
- The numerator sums the weights of all transactions containing the itemset, and  
- The denominator is the total weight of all transactions.

By using weighted support, transactions that represent higher monetary value have a larger influence on the frequency of itemsets. The Apriori algorithm’s candidate generation, pruning, and subsequent steps remain unchanged; only the support calculation is modified. This approach allows us to incorporate transaction importance without altering the core mechanisms of the Apriori algorithm.

---

# 总结

本作业的 **Part B** 详细讨论了如何利用进化算法改进聚类算法、计算不同变异操作下保持原状的概率、以及在无变异的算术交叉遗传算法（NoMutAritGA）中可达解的分析；同时也探讨了基于单调变换的目标函数对遗传算法行为的影响以及对比 DE 与 RS 在搜索全局最优解时的效率。  

**Part C** 则从实际交易数据出发，使用 Apriori 算法逐层生成候选项集与频繁项集，推导关联规则（包括支持度、置信度和提升度的计算），并讨论如何在考虑交易权重时调整支持度的计算方式，从而保证算法核心结构不变的情况下融入权重信息。

以上答案均基于理论分析和实际数据的推导，力求详尽、准确，适合作为提交给老师的作业答案。请根据课程要求的格式和提交要求对文档进行适当排版。  

如果有任何疑问或需要进一步修改的部分，请及时反馈。
