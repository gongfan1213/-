ä½ çš„é—®é¢˜ä»ç„¶æ˜¯ **NLTK punkt èµ„æºä¸¢å¤±** å’Œ **æ•°æ®é›†æ²¡æœ‰æ­£ç¡®åŠ è½½** å¯¼è‡´ `train_test_split()` å¤±è´¥ã€‚è®©æˆ‘ä»¬é€æ­¥è§£å†³é—®é¢˜ã€‚

---

## **ç¬¬ä¸€æ­¥ï¼šä¿®å¤ NLTK punkt èµ„æºä¸¢å¤±**
Colab å¯èƒ½æœ‰ç¼“å­˜é—®é¢˜ï¼Œå› æ­¤ä½ éœ€è¦å¼ºåˆ¶åˆ é™¤ `nltk_data` ç›®å½•å¹¶é‡æ–°ä¸‹è½½ `punkt` èµ„æºï¼š

```python
!rm -rf /root/nltk_data  # åˆ é™¤ NLTK å¯èƒ½æŸåçš„ç¼“å­˜
import nltk
nltk.download('punkt')  # é‡æ–°ä¸‹è½½ punkt èµ„æº
```
ç„¶å**é‡å¯ Colab è¿è¡Œæ—¶**ï¼ˆç‚¹å‡» `Runtime` -> `Restart runtime`ï¼‰ã€‚

---

## **ç¬¬äºŒæ­¥ï¼šæ£€æŸ¥æ•°æ®é›†æ˜¯å¦æ­£ç¡®åŠ è½½**
ä½ çš„é”™è¯¯ä¿¡æ¯ `Total samples loaded: 0` è¡¨æ˜ **æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½• txt æ–‡ä»¶**ã€‚è¯·è¿è¡Œä»¥ä¸‹ä»£ç æ£€æŸ¥æ•°æ®é›†è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼š

```python
import os

# ä½ çš„æ•°æ®é›†è·¯å¾„
data_dir = "/content/drive/MyDrive/dataset/dataset"

# ç¡®ä¿æ•°æ®é›†ç›®å½•å­˜åœ¨
if os.path.exists(data_dir):
    print("âœ… æ•°æ®é›†ç›®å½•å­˜åœ¨")
else:
    print("âŒ æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥è·¯å¾„")

# åˆ—å‡º dataset ç›®å½•ä¸­çš„æ–‡ä»¶å¤¹
print("ğŸ“‚ dataset ç›®å½•å†…å®¹ï¼š", os.listdir(data_dir))

# æ£€æŸ¥å­æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
categories = ['cakes', 'chocolate_bars', 'cookies', 'soft_drinks', 'teas']
for category in categories:
    category_path = os.path.join(data_dir, category)
    if os.path.exists(category_path):
        print(f"âœ… å‘ç°ç±»åˆ«æ–‡ä»¶å¤¹ï¼š{category}")
        print("ğŸ“œ æ–‡ä»¶åˆ—è¡¨ï¼ˆå‰5ä¸ªï¼‰ï¼š", os.listdir(category_path)[:5])
    else:
        print(f"âŒ æœªæ‰¾åˆ°ç±»åˆ«æ–‡ä»¶å¤¹ï¼š{category}")
```
#### **å¯èƒ½çš„æƒ…å†µ**
1. **å¦‚æœ `âŒ æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨`ï¼Œè¯´æ˜ `data_dir` è·¯å¾„é”™è¯¯**  
   - **è§£å†³æ–¹æ¡ˆï¼š** æ‰‹åŠ¨æ£€æŸ¥ Google Drive çš„å®é™…è·¯å¾„ï¼Œå¹¶æ›´æ–° `data_dir`ã€‚  
   - ä½ å¯ä»¥åœ¨ Colab è¿è¡Œ `!ls /content/drive/MyDrive/` æ‰¾åˆ°æ­£ç¡®çš„è·¯å¾„ã€‚

2. **å¦‚æœ `âŒ æœªæ‰¾åˆ°ç±»åˆ«æ–‡ä»¶å¤¹`ï¼Œè¯´æ˜ `dataset` ç›®å½•ç»“æ„é”™è¯¯**  
   - å¯èƒ½ä½  **è§£å‹åå°‘äº†ä¸€å±‚ç›®å½•**ï¼Œåº”è¯¥è¿›å…¥ `dataset/dataset/` è€Œä¸æ˜¯ `dataset/`ã€‚

3. **å¦‚æœ `âœ… æ•°æ®é›†ç›®å½•å­˜åœ¨` å¹¶åˆ—å‡ºäº† `txt` æ–‡ä»¶ï¼Œä½† `Total samples loaded: 0`**  
   - å¯èƒ½æ˜¯ `glob.glob(os.path.join(folder, '*.txt'))` å¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨åˆ—å‡º `txt` æ–‡ä»¶ï¼š
   ```python
   for category in categories:
       folder = os.path.join(data_dir, category)
       txt_files = glob.glob(os.path.join(folder, '*.txt'))
       if txt_files:
           print(f"âœ… {category} ç›®å½•ä¸­æ‰¾åˆ° {len(txt_files)} ä¸ª txt æ–‡ä»¶")
       else:
           print(f"âŒ {category} ç›®å½•ä¸­æ²¡æœ‰ txt æ–‡ä»¶")
   ```

---

## **ç¬¬ä¸‰æ­¥ï¼šè°ƒè¯•æ•°æ®åŠ è½½**
å¦‚æœ **æ•°æ®ç›®å½•æ­£ç¡®ä½† `Total samples loaded: 0`**ï¼Œä½ éœ€è¦ **å•ç‹¬æµ‹è¯• `txt` æ–‡ä»¶æ˜¯å¦èƒ½æ­£ç¡®è¯»å–**ï¼š

```python
import glob

# é€‰å–æŸä¸ªç±»åˆ«çš„æ–‡ä»¶å¤¹
test_category = "teas"  # ä½ å¯ä»¥æ¢æˆ "cakes", "cookies" ç­‰
test_folder = os.path.join(data_dir, test_category)

# è·å–æ–‡ä»¶åˆ—è¡¨
txt_files = glob.glob(os.path.join(test_folder, '*.txt'))

# è¯»å–å‰2ä¸ªæ–‡ä»¶çš„å†…å®¹
for txt_file in txt_files[:2]:
    try:
        with open(txt_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            print(f"\nğŸ“œ è¯»å–æ–‡ä»¶: {txt_file}")
            print("ğŸ”¹ ç¬¬ä¸€è¡Œï¼ˆæ ‡é¢˜ï¼‰ï¼š", lines[0].strip() if lines else "ç©ºæ–‡ä»¶")
            print("ğŸ”¹ æ€»è¡Œæ•°ï¼š", len(lines))
    except Exception as e:
        print(f"âŒ è¯»å– {txt_file} å¤±è´¥ï¼š{e}")
```
#### **å¯èƒ½çš„æƒ…å†µ**
1. **å¦‚æœ `txt_files=[]`ï¼Œè¯´æ˜ `glob.glob()` æ‰¾ä¸åˆ° `txt` æ–‡ä»¶**  
   - å¯èƒ½ `*.txt` åŒ¹é…æ¨¡å¼æœ‰è¯¯ï¼Œå°è¯• `print(os.listdir(test_folder))` æ£€æŸ¥å®é™…æ–‡ä»¶åã€‚

2. **å¦‚æœ `è¯»å–æ–‡ä»¶å¤±è´¥`ï¼Œè¯´æ˜æŸäº› `txt` æ–‡ä»¶ç¼–ç æœ‰é—®é¢˜**  
   - å¯èƒ½ `utf-8` è§£æå¤±è´¥ï¼Œå¯ä»¥å°è¯• `encoding="ISO-8859-1"` æˆ– `encoding="utf-16"`ã€‚

---

## **ç¬¬å››æ­¥ï¼šç¡®è®¤æ•°æ®é›†æ­£ç¡®åï¼Œé‡æ–°è¿è¡Œä»£ç **
å¦‚æœä¸Šè¿°æ£€æŸ¥ **æ‰€æœ‰éƒ½æ­£å¸¸**ï¼Œä½†ä»ç„¶ `Total samples loaded: 0`ï¼Œä½ å¯ä»¥è¿è¡Œå®Œæ•´çš„æ•°æ®åŠ è½½ä»£ç ï¼š

```python
import nltk
nltk.download('punkt')  # ç¡®ä¿ punkt èµ„æºå¯ç”¨
from nltk.tokenize import sent_tokenize
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('all-MiniLM-L6-v2')

# è®¡ç®—æ–‡æœ¬åµŒå…¥
def compute_text_embedding(text, max_sentences=10):
    sentences = sent_tokenize(text)
    selected = sentences[:max_sentences]
    weights = [3 if i < 5 else 1 for i in range(len(selected))]
    embeddings = model.encode(selected)
    weights = np.array(weights).reshape(-1, 1)
    return np.sum(embeddings * weights, axis=0) / np.sum(weights)

X_vectors = []
y_labels = []
titles = []

for label in categories:
    folder = os.path.join(data_dir, label)
    for filepath in glob.glob(os.path.join(folder, '*.txt')):
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                if not lines:
                    continue
                title = lines[0].strip()
                content = ' '.join([line.strip() for line in lines])
                vec = compute_text_embedding(content)
                X_vectors.append(vec)
                y_labels.append(label)
                titles.append(title)
        except Exception as e:
            print(f"âŒ è¯»å– {filepath} å¤±è´¥ï¼š{e}")

# è½¬æ¢ä¸º NumPy æ•°ç»„
X_vectors = np.array(X_vectors)
y_labels = np.array(y_labels)
titles = np.array(titles)

print("âœ… æˆåŠŸåŠ è½½æ ·æœ¬æ•°é‡ï¼š", len(X_vectors))
```
å¦‚æœè¿™ä¸€æ­¥ **æˆåŠŸåŠ è½½æ ·æœ¬**ï¼Œé‚£ä¹ˆä½ çš„ `train_test_split()` å°±ä¸ä¼šå†æŠ¥é”™äº†ã€‚

---

## **æ€»ç»“**
1. **å…ˆç¡®ä¿ NLTK punkt èµ„æºå¯ç”¨**
   ```python
   !rm -rf /root/nltk_data
   import nltk
   nltk.download('punkt')
   ```
   **ç„¶åé‡å¯ Colab è¿è¡Œæ—¶**ã€‚

2. **æ£€æŸ¥ `data_dir` æ˜¯å¦æ­£ç¡®**
   ```python
   print(os.listdir("/content/drive/MyDrive/dataset"))
   ```

3. **æµ‹è¯• `txt` æ–‡ä»¶æ˜¯å¦å¯è¯»**
   ```python
   for category in categories:
       folder = os.path.join(data_dir, category)
       print(f"ğŸ“‚ {category}: {os.listdir(folder)[:5]}")
   ```

4. **æµ‹è¯• `sent_tokenize()` æ˜¯å¦å¯ç”¨**
   ```python
   text = "This is a test sentence. Here is another one."
   print(sent_tokenize(text))
   ```

5. **å¦‚æœ `Total samples loaded: 0`ï¼Œè¿è¡Œå®Œæ•´çš„æ•°æ®åŠ è½½è°ƒè¯•ä»£ç **

è¯·é€æ­¥æ‰§è¡Œè¿™äº›æ­¥éª¤ï¼Œå¹¶å‘Šè¯‰æˆ‘å“ªä¸€æ­¥ä»ç„¶æœ‰é—®é¢˜ï¼Œæˆ‘ä¼šç»§ç»­å¸®åŠ©ä½ è§£å†³ï¼ğŸš€
