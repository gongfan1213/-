好的，我将在之前代码的基础上，添加更完整的文本数据特征提取、建模和预测部分。为了使代码更具通用性和可扩展性，我将：

1.  **使用 Pipeline:** 将特征提取和模型训练整合到一个 Pipeline 中，使代码更简洁，也方便进行参数调优。
2.  **支持多种模型:**  提供一个框架，可以轻松切换不同的分类模型（朴素贝叶斯、逻辑回归、支持向量机）。
3.  **模型评估:** 使用交叉验证进行更可靠的模型评估，并输出更详细的评估指标。
4.  **预测新数据：** 添加预测新文本数据情感的功能。
5. **参数调优：** 使用网格搜索来优化模型参数。

```python
import pandas as pd
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# 下载必要的NLTK资源（只需运行一次）
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('omw-1.4')
nltk.download('averaged_perceptron_tagger')
nltk.download('punkt')
nltk.download('punkt_tab')

# 加载数据
movies = pd.read_csv("./IMDB-Movie-Data.csv")

# 数据清洗函数 (与之前相同)
def clean_text(text):
    text = re.sub(r'[^a-zA-Z]', ' ', text)
    text = text.lower()
    words = nltk.word_tokenize(text)
    stop_words = set(stopwords.words('english'))
    words = [w for w in words if w not in stop_words]
    lemmatizer = WordNetLemmatizer()
    words = [lemmatizer.lemmatize(w) for w in words]
    text = ' '.join(words)
    return text

# 应用数据清洗
movies['Cleaned_Description'] = movies['Description'].apply(clean_text)

# 创建示例数据（假设已经手动标注了前200条，或者你自己标注）
movies['Manual_Sentiment'] = ''
movies.loc[0:66, 'Manual_Sentiment'] = 'Positive'
movies.loc[67:132, 'Manual_Sentiment'] = 'Negative'
movies.loc[133:200, 'Manual_Sentiment'] = 'Neutral'

# 划分训练集和测试集（只使用已标注的数据）
labeled_data = movies[movies['Manual_Sentiment'] != '']
X_train, X_test, y_train, y_test = train_test_split(
    labeled_data['Cleaned_Description'],
    labeled_data['Manual_Sentiment'],
    test_size=0.2,
    random_state=42
)

# 定义一个函数来创建Pipeline和进行模型训练、评估
def train_and_evaluate_model(classifier, X_train, y_train, X_test, y_test, use_grid_search=False):

    # 创建Pipeline
    pipeline = Pipeline([
        ('tfidf', TfidfVectorizer(min_df=2)),  # 添加 min_df
        ('clf', classifier),
    ])

    # 参数网格 (用于GridSearchCV)
    param_grid = {}
    if isinstance(classifier, MultinomialNB):
        param_grid = {
            'tfidf__max_features': [1000, 2000, 5000],
            'tfidf__ngram_range': [(1, 1), (1, 2)],  # 尝试不同的 n-gram 范围
            'clf__alpha': [0.1, 1.0, 10.0],
        }
    elif isinstance(classifier, LogisticRegression):
        param_grid = {
            'tfidf__max_features': [1000, 2000, 5000],
            'tfidf__ngram_range': [(1, 1), (1, 2)],
            'clf__C': [0.1, 1.0, 10.0],
            'clf__solver': ['liblinear', 'lbfgs'], #添加不同的求解器
        }
    elif isinstance(classifier, SVC):
        param_grid = {
            'tfidf__max_features': [1000, 2000, 5000],
            'tfidf__ngram_range': [(1, 1), (1, 2)],
            'clf__C': [0.1, 1.0, 10.0],
            'clf__kernel': ['linear', 'rbf'],
        }

    # 使用GridSearchCV进行参数调优（如果启用）
    if use_grid_search:
        grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)
        grid_search.fit(X_train, y_train)
        best_model = grid_search.best_estimator_
        print("Best Parameters:", grid_search.best_params_)
    else:
        best_model = pipeline.fit(X_train, y_train)

    # 交叉验证评估
    cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='accuracy')
    print("Cross-Validation Accuracy Scores:", cv_scores)
    print("Mean CV Accuracy:", cv_scores.mean())

    # 在测试集上评估
    y_pred = best_model.predict(X_test)
    print("Test Set Accuracy:", accuracy_score(y_test, y_pred))
    print(classification_report(y_test, y_pred))
    print(confusion_matrix(y_test, y_pred))

    return best_model

# 选择并训练模型 (以朴素贝叶斯为例，你可以更换为其他模型)
model = train_and_evaluate_model(MultinomialNB(), X_train, y_train, X_test, y_test, use_grid_search=True)
#model = train_and_evaluate_model(LogisticRegression(), X_train, y_train, X_test, y_test, use_grid_search=True)
#model = train_and_evaluate_model(SVC(), X_train, y_train, X_test, y_test, use_grid_search=True)


# 预测新文本的情感
def predict_sentiment(text, model):
    cleaned_text = clean_text(text)
    sentiment = model.predict([cleaned_text])[0]
    return sentiment

# 示例文本
new_text = "This movie was absolutely amazing! The acting was superb, and the plot was captivating."
predicted_sentiment = predict_sentiment(new_text, model)
print(f"The sentiment of the new text is: {predicted_sentiment}")

new_text2 = "I hated this film.  It was boring and pointless"
predicted_sentiment2 = predict_sentiment(new_text2, model)
print(f"The sentiment of the new text is: {predicted_sentiment2}")

# 使用训练好的模型预测所有电影的情感（可选）
movies['Predicted_Sentiment'] = movies['Cleaned_Description'].apply(lambda x: predict_sentiment(x, model))

#如果需要可以把机器学习预测的情感列改名为'Sentiment'
movies.rename(columns={'Predicted_Sentiment': 'Sentiment'}, inplace=True)
```

**代码解释:**

1.  **`train_and_evaluate_model` 函数:**
    *   接收分类器、训练数据、测试数据和是否使用网格搜索的标志作为输入。
    *   创建一个 `Pipeline`，将 `TfidfVectorizer` 和分类器连接起来。
    *   定义一个 `param_grid` 字典，用于指定要调优的参数。不同的分类器有不同的参数。
    *   如果 `use_grid_search` 为 `True`，则使用 `GridSearchCV` 进行参数调优。
    *   使用交叉验证评估模型。
    *   在测试集上评估模型，并输出准确率、分类报告和混淆矩阵。
    *   返回训练好的模型。

2.  **选择并训练模型:**
    *   调用 `train_and_evaluate_model` 函数，传入你选择的分类器（这里以 `MultinomialNB` 为例）。你可以取消注释其他模型（`LogisticRegression`, `SVC`）来尝试它们。
    *   设置`use_grid_search=True` 来启用参数调优。

3.  **`predict_sentiment` 函数:**
    *   接收一个文本字符串和训练好的模型作为输入。
    *   对文本进行清洗。
    *   使用模型预测情感。
    *   返回预测的情感标签。

4.  **预测新文本情感：**
    * 提供两个示例文本
    * 调用`predict_sentiment`预测情感
    * 打印输出

5. **预测所有电影的情感（可选）：**
    *   使用训练好的模型和`predict_sentiment`函数预测所有电影的情感。
    *  把机器学习预测的情感列改名为'Sentiment'

现在，你拥有了一个更完整、更健壮的文本情感分析流程。你可以：

*   尝试不同的分类模型（朴素贝叶斯、逻辑回归、支持向量机）。
*   调整 `TfidfVectorizer` 的参数（`max_features`, `min_df`, `ngram_range`）。
*   调整分类器的参数（通过修改 `param_grid`）。
*   使用 `predict_sentiment` 函数预测任何新文本的情感。

这应该能更好地满足你作业的要求，并获得更高的分数！
