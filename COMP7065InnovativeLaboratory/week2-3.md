> ğŸ’­ å¥½çš„ï¼Œé¦–å…ˆæˆ‘éœ€è¦å¤„ç†ç”¨æˆ·çš„è¦æ±‚ã€‚ç”¨æˆ·å¸Œæœ›å°†ä¹‹å‰æä¾›çš„è‹±æ–‡æŠ€æœ¯å†…å®¹ç¿»è¯‘æˆä¸­æ–‡å¹¶è¿›è¡Œè®²è§£ã€‚æˆ‘å¿…é¡»ç¡®ä¿ç¿»è¯‘å‡†ç¡®ï¼ŒåŒæ—¶è®²è§£è¦æ¸…æ™°æ˜“æ‡‚ï¼Œé€‚åˆä¸­æ–‡è¯»è€…ç†è§£ã€‚
>
> é¦–å…ˆï¼Œæˆ‘ä¼šé€šè¯»æ•´ä¸ªè‹±æ–‡å†…å®¹ï¼Œç†è§£æ¯ä¸ªéƒ¨åˆ†çš„ç›®çš„å’Œé€»è¾‘ã€‚æ¡ˆä¾‹ç ”ç©¶ä¸»è¦æ¶‰åŠä»ä¸‹è½½æ•°æ®é›†åˆ°æ„å»ºæ¨¡å‹ã€è®­ç»ƒå’Œè¯„ä¼°çš„å®Œæ•´æµç¨‹ã€‚éœ€è¦æ³¨æ„æŠ€æœ¯æœ¯è¯­çš„å‡†ç¡®ç¿»è¯‘ï¼Œæ¯”å¦‚â€œdatasetâ€ã€â€œDataLoaderâ€ã€â€œtransformsâ€ç­‰ï¼Œè¿™äº›åœ¨æ·±åº¦å­¦ä¹ æ¡†æ¶å¦‚PyTorchä¸­æœ‰å›ºå®šè¯‘æ³•ã€‚
>
> æ¥ä¸‹æ¥æ˜¯ä»£ç éƒ¨åˆ†çš„ç¿»è¯‘ã€‚ä¾‹å¦‚ï¼Œâ€œFaceLandmarksDatasetâ€ç±»éœ€è¦ç¿»è¯‘æˆâ€œé¢éƒ¨å…³é”®ç‚¹æ•°æ®é›†â€ï¼ŒåŒæ—¶ä¿æŒç±»ååœ¨ä»£ç ä¸­çš„å®Œæ•´æ€§ã€‚æ³¨é‡Šä¹Ÿéœ€è¦è½¬æˆä¸­æ–‡ï¼Œä½†è¦æ³¨æ„ä¿ç•™å˜é‡åå’Œå‡½æ•°åä¸å˜ï¼Œä»¥å…å½±å“ä»£ç è¿è¡Œã€‚
>
> åœ¨è®²è§£è¿‡ç¨‹ä¸­ï¼Œéœ€è¦åˆ†æ­¥éª¤è§£é‡Šæ¯ä¸ªæ¨¡å—çš„åŠŸèƒ½ã€‚æ¯”å¦‚æ•°æ®é›†çš„ä¸‹è½½å’Œæå–ï¼Œæ•°æ®é›†çš„æ„å»ºæµç¨‹ï¼Œä»¥åŠå„é¡¹æ•°æ®é¢„å¤„ç†æ“ä½œçš„ä½œç”¨ï¼Œå¦‚è£å‰ªã€ç¼©æ”¾å’Œæ ‡å‡†åŒ–ã€‚å¯¹äºä¸ç†Ÿæ‚‰PyTorchçš„è¯»è€…ï¼Œå¯èƒ½éœ€è¦ç®€è¦ä»‹ç»DataLoaderå’ŒDatasetçš„æ¦‚å¿µã€‚
>
> æ¨¡å‹å®šä¹‰éƒ¨åˆ†ï¼ŒMobileNetV2ä½œä¸ºé¢„è®­ç»ƒæ¨¡å‹ï¼Œæ›¿æ¢æœ€åä¸€å±‚ä»¥é€‚é…å…³é”®ç‚¹æ£€æµ‹ä»»åŠ¡ã€‚è¿™éƒ¨åˆ†éœ€è¦è§£é‡Šé¢„è®­ç»ƒæ¨¡å‹çš„åº”ç”¨ä»¥åŠå¦‚ä½•è°ƒæ•´è¾“å‡ºå±‚ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°ï¼ˆMSEï¼‰å’Œä¼˜åŒ–å™¨ï¼ˆAdamï¼‰çš„é€‰æ‹©ä¹Ÿæ˜¯é‡ç‚¹ï¼Œéœ€è¯´æ˜å…¶é€‚ç”¨æ€§ã€‚
>
> è®­ç»ƒå’Œè¯„ä¼°å¾ªç¯éƒ¨åˆ†è¦å¼ºè°ƒæ¨¡å‹å¦‚ä½•ä»æ•°æ®ä¸­å­¦ä¹ ï¼Œä»¥åŠå¦‚ä½•éªŒè¯æ€§èƒ½ã€‚éœ€è®²è§£è®­ç»ƒè¿‡ç¨‹ä¸­çš„å…³é”®æ­¥éª¤ï¼Œå¦‚æ¢¯åº¦å½’é›¶ã€å‰å‘ä¼ æ’­ã€æŸå¤±è®¡ç®—å’Œåå‘ä¼ æ’­ã€‚è¯„ä¼°é˜¶æ®µåˆ™æ¶‰åŠæ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„è¡¨ç°ï¼Œå¯èƒ½æ¶‰åŠå‡†ç¡®æ€§å’Œè¯¯å·®åˆ†æã€‚
>
> æœ€åï¼Œç»“æœå¯è§†åŒ–çš„éƒ¨åˆ†éœ€è¦ç”¨å›¾ç¤ºè¯´æ˜é¢„æµ‹å…³é”®ç‚¹ä¸çœŸå®å€¼çš„å¯¹æ¯”ï¼Œè¯„ä»·æŒ‡æ ‡å¦‚æ¬§æ°è·ç¦»å¯ä»¥å¸®åŠ©è¯»è€…ç†è§£æ¨¡å‹æ€§èƒ½ã€‚éœ€è¦æ³¨æ„ä»£ç ä¸­çš„ç»˜å›¾å‡½æ•°æ˜¯å¦åœ¨ç¿»è¯‘åä»èƒ½æ­£ç¡®æ‰§è¡Œï¼Œæ¯”å¦‚matplotlibçš„ä½¿ç”¨ã€‚
>
> ç¿»è¯‘è¿‡ç¨‹ä¸­è¦ä¿æŒæŠ€æœ¯ç»†èŠ‚çš„å‡†ç¡®æ€§ï¼ŒåŒæ—¶è¯­è¨€è¦é€šé¡ºè‡ªç„¶ï¼Œé¿å…ç›´è¯‘å¯¼è‡´çš„ç”Ÿç¡¬ã€‚å¯èƒ½å­˜åœ¨çš„ä¸€äº›æŒ‘æˆ˜åŒ…æ‹¬ä¸“æœ‰åè¯çš„è¯‘æ³•ï¼ˆå¦‚DataLoaderåº”ä¸ºæ•°æ®åŠ è½½å™¨ï¼‰åŠä»£ç æ³¨é‡Šæ ¼å¼çš„æ­£ç¡®å¤„ç†ã€‚è¿˜éœ€è¦ç¡®ä¿ä»£ç å—ä¸­çš„å˜é‡åã€å‡½æ•°åä¿æŒä¸å˜ï¼Œé˜²æ­¢ä½¿ç”¨è€…è¿è¡Œä»£ç æ—¶å‡ºé”™ã€‚
>
> æ€»ä¹‹ï¼Œéœ€è¦ç³»ç»Ÿåœ°åˆ†æå’Œç»„ç»‡åŸæ–‡å†…å®¹ï¼Œåˆ†æ¨¡å—è¿›è¡Œç¿»è¯‘å’Œè®²è§£ï¼Œç»“åˆä»£ç å®ä¾‹å’Œç†è®ºè§£é‡Šï¼Œä½¿ä¸­æ–‡è¯»è€…èƒ½å¤Ÿå…¨é¢ç†è§£æ•´ä¸ªæ¡ˆä¾‹ç ”ç©¶çš„æµç¨‹å’ŒæŠ€æœ¯è¦ç‚¹ã€‚
>
> 



ä»¥ä¸‹æ˜¯ä¸Šè¿°è‹±æ–‡å†…å®¹çš„ä¸­æ–‡è®²è§£ç¿»è¯‘ï¼š

---

### **æ¡ˆä¾‹ç ”ç©¶è§£æï¼šåŸºäºé¢„è®­ç»ƒæ¨¡å‹çš„5ç‚¹é¢éƒ¨å…³é”®ç‚¹æ£€æµ‹**

---

### **1. æ•°æ®é›†å‡†å¤‡**
#### æ•°æ®é›†ä¸‹è½½ä¸è§£å‹
```python
def download_and_extract_zip(url):
    # é€šè¿‡URLä¸‹è½½å¹¶è§£å‹æ•°æ®é›†
    filename = url.split('/')[-1]
    urllib.request.urlretrieve(url, filename)
    with zipfile.ZipFile(filename, 'r') as zip_ref:
        zip_ref.extractall()
    os.remove(filename)

download_and_extract_zip("http://mmlab.ie.cuhk.edu.hk/archive/CNN/data/train.zip")
```
- **åŠŸèƒ½**ï¼šä»æŒ‡å®šURLä¸‹è½½ZIPæ ¼å¼çš„æ•°æ®é›†ï¼Œè§£å‹åˆ°å½“å‰ç›®å½•ï¼Œå¹¶åˆ é™¤åŸå§‹å‹ç¼©åŒ…ã€‚
- **è¾“å…¥æ–‡ä»¶ç»“æ„**ï¼š
  ```
  lfw_5590/      # è®­ç»ƒå›¾åƒæ–‡ä»¶å¤¹
  net_7876/      # æµ‹è¯•å›¾åƒæ–‡ä»¶å¤¹ï¼ˆå‡è®¾ï¼‰
  trainImageList.txt   # è®­ç»ƒé›†æ ‡æ³¨æ–‡ä»¶
  testImageList.txt    # æµ‹è¯•é›†æ ‡æ³¨æ–‡ä»¶
  ```

---

### **2. æ•°æ®é›†æ„å»º**
#### è‡ªå®šä¹‰Datasetç±»
```python
class FaceLandmarksDataset(Dataset):
    def __init__(self, annotations_file, img_dir, transform=None):
        # å®šä¹‰æ•°æ®åˆ—å
        columns = ['image_path', 'bbox_x1', 'bbox_x2', ..., 'landmark5_y']
        self.df = pd.read_csv(annotations_file, delimiter=' ', names=columns)
        # æ¸…ç†è·¯å¾„æ ¼å¼å¹¶å°†å›¾åƒè·¯å¾„æ‹¼æ¥ä¸ºå®Œæ•´è·¯å¾„
        self.df['image_path'] = self.df['image_path'].str.replace('\\', '/').apply(
            lambda x: os.path.join(img_dir, x))
        self.transform = transform

    def __getitem__(self, idx):
        image = read_image(self.df.iloc[idx, 0])  # ä½¿ç”¨PyTorchè¯»å–å›¾åƒä¸ºTensoræ ¼å¼
        bbox = np.array([x1, y1, x2, y2])        # æå–è¾¹ç•Œæ¡†åæ ‡
        landmarks = np.array([x1,y1, x2,y2, ..., x5,y5]).reshape(5,2)  # æå–5ä¸ªå…³é”®ç‚¹åæ ‡
        sample = {'image': image, 'bbox': bbox, 'landmarks': landmarks}
        if self.transform:  # åº”ç”¨æ•°æ®å¢å¼ºï¼ˆå¦‚æœéœ€è¦ï¼‰
            sample = self.transform(sample)
        return sample
```
- **å…³é”®æ­¥éª¤**ï¼š
  1. **è¯»å–æ ‡æ³¨æ–‡ä»¶**ï¼šæ¯è¡Œæ•°æ®æ ¼å¼ä¸º `å›¾åƒè·¯å¾„` + `äººè„¸æ¡†åæ ‡` + `5ç‚¹å…³é”®ç‚¹åæ ‡`ã€‚
  2. **å›¾åƒè·¯å¾„å¤„ç†**ï¼šå°†Windowsé£æ ¼åæ–œæ è·¯å¾„`\`æ›¿æ¢ä¸ºUnixæ–œæ `/`ï¼Œå¹¶æ‹¼æ¥ä¸ºç»å¯¹è·¯å¾„ã€‚
  3. **æ•°æ®æå–ä¸å˜æ¢**ï¼šå°†å›¾åƒã€è¾¹ç•Œæ¡†å’Œå…³é”®ç‚¹å°è£…ä¸ºæ ·æœ¬å­—å…¸ï¼Œæ”¯æŒåç»­ç®¡é“åŒ–å¤„ç†ã€‚

---

### **3. æ•°æ®é¢„å¤„ç†æµç¨‹**

#### ï¼ˆ1ï¼‰è£å‰ªäººè„¸åŒºåŸŸ
```python
class BBoxCrop(object):
    def __call__(self, sample):
        image, bbox, landmarks = sample.values()
        x1, y1, x2, y2 = bbox  # æ ¹æ®è¾¹ç•Œæ¡†è£å‰ªå›¾åƒ
        image = image[:, y1:y2, x1:x2]
        landmarks -= [x1, y1]  # å…³é”®ç‚¹åæ ‡éœ€åŒæ­¥åç§»
        return {'image': image, 'landmarks': landmarks}
```
- **ç›®çš„**ï¼šä»…ä¿ç•™äººè„¸åŒºåŸŸï¼Œå‡å°‘èƒŒæ™¯å¹²æ‰°ï¼Œè°ƒæ•´å…³é”®ç‚¹åæ ‡åˆ°è£å‰ªåçš„åæ ‡ç³»ã€‚

#### ï¼ˆ2ï¼‰ç¼©æ”¾è‡³å›ºå®šå°ºå¯¸
```python
class Rescale(object):
    def __init__(self, output_size=(224,224)):
        self.output_size = output_size

    def __call__(self, sample):
        image, landmarks = sample['image'], sample['landmarks']
        new_h, new_w = self.output_size
        image = F.resize(image, (new_h, new_w))  # ä½¿ç”¨PyTorchçš„resizeå‡½æ•°
        landmarks *= [new_w / w, new_h / h]      # æŒ‰æ¯”ä¾‹ç¼©æ”¾å…³é”®ç‚¹åæ ‡
        return {'image': image, 'landmarks': landmarks}
```
- **è¯´æ˜**ï¼šç»Ÿä¸€è¾“å…¥å°ºå¯¸ä¸º224Ã—224ï¼ˆé€‚é…MobileNetV2çš„è¾“å…¥è¦æ±‚ï¼‰ã€‚

#### ï¼ˆ3ï¼‰æ ‡å‡†åŒ–ä¸Tensorè½¬æ¢
```python
class ToTensor(object):
    def __call__(self, sample):
        image, landmarks = sample['image'], sample['landmarks']
        return {
            'image': (image / 255.0).to(device),  # å½’ä¸€åŒ–åˆ°[0,1]åŒºé—´å¹¶ä¼ è¾“åˆ°GPU
            'landmarks': (landmarks / 224).to(torch.float32)  # å½’ä¸€åŒ–å¹¶è½¬ä¸ºæµ®ç‚¹Tensor
        }
```
- **å…³é”®ç‚¹å½’ä¸€åŒ–**ï¼šå°†åæ ‡å€¼ç¼©æ”¾åˆ°[0,1]åŒºé—´ï¼Œåˆ©äºæ¨¡å‹è®­ç»ƒæ”¶æ•›ã€‚

---

### **4. æ•°æ®åŠ è½½å™¨é…ç½®**
```python
# ç»„åˆé¢„å¤„ç†æµç¨‹
transforms = Compose([BBoxCrop(), Rescale((224,224)), ToTensor(device='cuda')])

# åˆ›å»ºDatasetå’ŒDataLoader
train_dataset = FaceLandmarksDataset(
    annotations_file='trainImageList.txt', img_dir='./', transform=transforms
)
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
```
- **åŠŸèƒ½**ï¼šå°†é¢„å¤„ç†æ­¥éª¤ä¸²è”æˆä¸€ä¸ªæµç¨‹ï¼Œæ‰¹é‡åŠ è½½æ•°æ®åˆ°GPUè¿›è¡Œé«˜æ•ˆè®­ç»ƒã€‚

---

### **5. æ¨¡å‹å®šä¹‰ä¸è®­ç»ƒ**

#### ï¼ˆ1ï¼‰é¢„è®­ç»ƒMobileNetV2æ¨¡å‹å¾®è°ƒ
```python
model = torchvision.models.mobilenet_v2(pretrained=True)
model.classifier[1] = nn.Linear(1280, 10)  # ä¿®æ”¹æœ€åä¸€å±‚ä¸º10ç»´è¾“å‡ºï¼ˆ5å…³é”®ç‚¹Ã—2ï¼‰
model = model.to('cuda')  # è¿ç§»åˆ°GPU
```
- **ç»“æ„æ”¹è¿›**ï¼šåŸå§‹æ¨¡å‹è¾“å‡ºåˆ†ç±»ç»“æœï¼Œæ­¤å¤„æ”¹ä¸ºå›å½’ä»»åŠ¡ï¼Œè¾“å‡º10ä¸ªæ•°ï¼ˆå¯¹åº”5ä¸ªç‚¹çš„x,yåæ ‡ï¼‰ã€‚

#### ï¼ˆ2ï¼‰æŸå¤±å‡½æ•°ä¸ä¼˜åŒ–å™¨
```python
criterion = nn.MSELoss()  # å‡æ–¹è¯¯å·®æŸå¤±ï¼ˆå›å½’é—®é¢˜ï¼‰
optimizer = optim.Adam(model.parameters(), lr=0.001)  # è‡ªé€‚åº”å­¦ä¹ ç‡ä¼˜åŒ–å™¨
```

#### ï¼ˆ3ï¼‰è®­ç»ƒå¾ªç¯
```python
model.train()
for epoch in range(10):
    for batch in train_loader:
        images = batch['image']  # Shape: [B,3,224,224]
        landmarks = batch['landmarks'].view(-1, 10)  # è°ƒæ•´å½¢çŠ¶ä¸º[B,10]
        outputs = model(images)
        loss = criterion(outputs, landmarks)
        loss.backward()  # åå‘ä¼ æ’­æ¢¯åº¦
        optimizer.step()
        optimizer.zero_grad()
```

---

### **6. è¯„ä¼°ä¸å¯è§†åŒ–**
#### å…³é”®ç‚¹æ¬§æ°è·ç¦»è®¡ç®—
```python
def euclidean_dist(pred, target):
    pred = pred.view(-1,5,2)  # [B,5,2]
    target = target.view(-1,5,2)
    dist = torch.sqrt(((pred - target)**2).sum(dim=2))  # é€ç‚¹è®¡ç®—è·ç¦»
    normalized_dist = dist / eye_dist  # è‹¥ä»¥ä¸¤çœ¼é—´è·ä¸ºåŸºå‡†ï¼Œåšå½’ä¸€åŒ–
    return dist.mean(), normalized_dist.mean()
```

#### å¯è§†åŒ–é¢„æµ‹ç»“æœ
```python
model.eval()
with torch.no_grad():
    batch = next(iter(test_loader))
    preds = model(batch['image']) * 224  # åå½’ä¸€åŒ–åˆ°åŸå›¾å°ºå¯¸
    targets = batch['landmarks'] * 224

    for i in range(4):
        plt.subplot(2,2,i+1)
        plt.imshow(batch['image'][i].cpu().permute(1,2,0))
        plt.scatter(targets[i,:,0], targets[i,:,1], c='g', label='çœŸå®ç‚¹')
        plt.scatter(preds[i,:,0], preds[i,:,1], c='r', marker='x', label='é¢„æµ‹ç‚¹')
```

---

### **æ€»ç»“**
è¯¥æ¡ˆä¾‹å®Œæ•´å±•ç¤ºäº†ï¼š
1. **æ•°æ®å‡†å¤‡**ï¼šä»åŸå§‹å›¾åƒä¸æ ‡æ³¨æ–‡ä»¶æ„å»ºDatasetã€‚
2. **é¢„å¤„ç†**ï¼šè£å‰ªã€æ ‡å‡†åŒ–ã€Tensorè½¬æ¢ã€‚
3. **æ¨¡å‹å¾®è°ƒ**ï¼šåŸºäºMobileNetV2çš„å›å½’ä»»åŠ¡è¿ç§»å­¦ä¹ ã€‚
4. **è®­ç»ƒä¸è¯„ä¼°**ï¼šæŸå¤±å‡½æ•°è®¾è®¡ã€è®­ç»ƒå¾ªç¯ã€å…³é”®ç‚¹è¯¯å·®è¡¡é‡ä¸å¯è§†åŒ–ã€‚

å…³é”®ç‚¹æ£€æµ‹çš„å¸¸è§æ”¹è¿›æ–¹å‘åŒ…æ‹¬ï¼š
- **æ•°æ®å¢å¼º**ï¼šæ·»åŠ éšæœºæ—‹è½¬ã€ç¿»è½¬å¢åŠ é²æ£’æ€§ã€‚
- **å¤šä»»åŠ¡å­¦ä¹ **ï¼šè”åˆæ£€æµ‹äººè„¸æ¡†å’Œå…³é”®ç‚¹ã€‚
- **æ¨¡å‹è½»é‡åŒ–**ï¼šä½¿ç”¨æ›´å°çš„ç½‘ç»œï¼ˆå¦‚MobileNetV3ï¼‰æå‡æ¨ç†é€Ÿåº¦ã€‚
