以下是对你提供的内容的详细讲解，包括数据预处理、训练和测试集划分，以及如何构建 PyTorch 的 `DataLoader` 来为 RNN 模型准备数据。

---

## **1. 数据预处理**

在训练 RNN 模型之前，我们需要对数据进行预处理。以下是具体步骤：

### **1.1 目标变量**
目标变量是我们希望模型预测的值。在这里，我们将目标变量设置为未来的收盘价（`Close`），并通过将 `Close` 列向后移动一定的时间步（`hrsPerDay`）来构造目标变量。

#### **代码实现**
```python
# 定义目标变量的偏移量
target_offset = -hrsPerDay  # 每天的交易小时数

# 构造目标变量
aapl['Target'] = aapl['Close'].shift(target_offset)

# 打印前几行数据
print(aapl[['Close', 'Target']].head(10))
```

---

### **1.2 数据归一化**
为了让模型更快收敛，我们使用 `MinMaxScaler` 将数据缩放到 [0, 1] 的范围。这里我们直接用 Pandas 的操作实现归一化。

#### **代码实现**
```python
# 数据归一化
aapl = (aapl - aapl.min()) / (aapl.max() - aapl.min())

# 删除缺失值
aapl.dropna(inplace=True)

# 打印归一化后的数据
print(aapl.head())
```

---

## **2. 训练和测试集划分**

我们有 730 天的股票数据。按照 80% 和 20% 的比例划分训练集和测试集。

#### **代码实现**
```python
# 按 80% 和 20% 划分训练集和测试集
train_size = int(len(aapl) * 0.8)
train_df = aapl[:train_size]
test_df = aapl[train_size:]

# 打印训练集和测试集的大小
print(f"Training data size: {len(train_df)}")
print(f"Testing data size: {len(test_df)}")
```

---

## **3. 构建 PyTorch 的 DataLoader**

为了训练 RNN 模型，我们需要将数据转换为 PyTorch 的 `DataLoader` 格式。以下是具体步骤：

### **3.1 定义超参数**
我们需要定义以下超参数：
- `sequence_size`：输入序列的长度（例如 5 天的交易数据）。
- `batch_size`：每个批次的样本数量。
- `features_size`：输入特征的数量。

#### **代码实现**
```python
import numpy as np
import torch
from torch import Tensor
from torch.utils.data import Dataset, DataLoader

# 定义超参数
sequence_size = hrsPerDay * 5  # 5 天的交易数据
batch_size = 256
features_size = len(train_df.drop(['Target'], axis=1).columns)
```

---

### **3.2 自定义 Dataset 类**
我们需要定义一个自定义的 `Dataset` 类，用于将数据转换为序列格式。

#### **代码实现**
```python
class SequenceDataset(Dataset):
    def __init__(self, df=pd.DataFrame(), label='', sequence_size=30):
        """
        初始化数据集
        :param df: 数据框
        :param label: 目标变量的列名
        :param sequence_size: 输入序列的长度
        """
        self.df = df
        self.label = label
        self.sequence_size = sequence_size

    def __len__(self):
        """
        返回数据集的长度
        """
        return len(self.df) - self.sequence_size

    def __getitem__(self, idx):
        """
        获取一个样本
        :param idx: 索引
        :return: (输入序列, 目标值)
        """
        if torch.is_tensor(idx):
            idx = idx.tolist()

        # 获取输入序列
        seq = Tensor(np.array(self.df.drop(self.label, axis=1).iloc[idx:idx+self.sequence_size, :], dtype=float))
        # 获取目标值
        label = Tensor(np.array(self.df[[self.label]].iloc[idx+self.sequence_size, :], dtype=float))

        return (seq, label)
```

---

### **3.3 构建 DataLoader**
使用 `SequenceDataset` 类构建训练集和测试集的 `DataLoader`。

#### **代码实现**
```python
# 构建训练集和测试集的 DataLoader
train_loader = DataLoader(
    SequenceDataset(train_df, label='Target', sequence_size=sequence_size),
    batch_size=batch_size,
    shuffle=True
)

test_loader = DataLoader(
    SequenceDataset(test_df, label='Target', sequence_size=sequence_size),
    batch_size=batch_size,
    shuffle=False
)

# 打印 DataLoader 的大小
print(f"Number of training batches: {len(train_loader)}")
print(f"Number of testing batches: {len(test_loader)}")
```

---

## **4. 验证 DataLoader**

为了确保 `DataLoader` 构建正确，我们可以从 `train_loader` 中取出一个批次的数据，并打印其形状。

#### **代码实现**
```python
# 从训练集 DataLoader 中取出一个批次的数据
for batch_idx, (seq, label) in enumerate(train_loader):
    print(f"Batch {batch_idx + 1}:")
    print(f"Input sequence shape: {seq.shape}")  # (batch_size, sequence_size, features_size)
    print(f"Label shape: {label.shape}")  # (batch_size, 1)
    break
```

#### **输出示例**
```plaintext
Batch 1:
Input sequence shape: torch.Size([256, 35, 10])  # 256 个样本，每个样本有 35 个时间步，每个时间步有 10 个特征
Label shape: torch.Size([256, 1])  # 256 个样本，每个样本有 1 个目标值
```

---

## **5. 总结**

### **5.1 数据预处理**
- 构造目标变量：将 `Close` 列向后移动一定的时间步。
- 数据归一化：将数据缩放到 [0, 1] 的范围。

### **5.2 数据划分**
- 按 80% 和 20% 的比例划分训练集和测试集。

### **5.3 构建 DataLoader**
- 自定义 `SequenceDataset` 类，将数据转换为序列格式。
- 使用 PyTorch 的 `DataLoader` 构建训练集和测试集。

通过这些步骤，我们已经为 RNN 模型准备好了数据。如果你需要进一步的帮助或有其他问题，请随时告诉我！
