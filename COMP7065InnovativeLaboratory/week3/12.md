以下是对你提供的内容的详细讲解，包括数据分割、构建 PyTorch 的 `DataLoader`、构建 RNN 模型、定义损失函数和优化器、训练模型，以及可视化结果的完整实现和解释。

---

## **1. 数据分割**

在训练模型之前，我们需要将数据分为训练集和测试集。这里我们将 80% 的数据用于训练，20% 的数据用于测试。

### **代码实现**
```python
# 定义测试集的大小
testDays = int(730 * 0.2 * hrsPerDay)  # 20% 的数据作为测试集

# 划分训练集和测试集
train_df = msft.iloc[:-testDays]  # 训练集
test_df = msft.iloc[-testDays:]   # 测试集

# 打印训练集和测试集的大小
print(f"Training data size: {len(train_df)}")
print(f"Testing data size: {len(test_df)}")

# 可视化训练集的目标变量
plt.figure(figsize=(18, 6))
train_df['Target'].plot()
plt.title("Training Data Target Variable")
plt.xlabel("Index")
plt.ylabel("Target")
plt.show()
```

---

## **2. 构建 PyTorch 的 DataLoader**

我们将使用之前定义的 `SequenceDataset` 类来构建训练集和测试集的 `DataLoader`。

### **代码实现**
```python
import numpy as np
import torch
from torch import nn, Tensor
from torch.utils.data import Dataset, DataLoader

# 定义超参数
sequence_size = hrsPerDay * 5  # 5 天的交易数据
batch_size = 256
features_size = len(train_df.drop(['Target'], axis=1).columns)

# 自定义 SequenceDataset 类
class SequenceDataset(Dataset):
    def __init__(self, df=pd.DataFrame(), label='', sequence_size=30):
        self.df = df
        self.label = label
        self.sequence_size = sequence_size

    def __len__(self):
        return len(self.df) - self.sequence_size

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()

        seq = Tensor(np.array(self.df.drop(self.label, axis=1).iloc[idx:idx+self.sequence_size, :], dtype=float))
        label = Tensor(np.array(self.df[[self.label]].iloc[idx+self.sequence_size, :], dtype=float))

        return (seq, label)

# 构建训练集和测试集的 DataLoader
train_loader = DataLoader(SequenceDataset(train_df, label='Target', sequence_size=sequence_size), batch_size=batch_size, shuffle=True)
test_loader = DataLoader(SequenceDataset(test_df, label='Target', sequence_size=sequence_size), batch_size=batch_size, shuffle=False)

# 打印 DataLoader 的大小
print(f"Number of training batches: {len(train_loader)}")
print(f"Number of testing batches: {len(test_loader)}")
```

---

## **3. 构建 RNN 模型**

我们将使用两层 GRU 和两层全连接层构建 RNN 模型。

### **代码实现**
```python
hiddenSize = 256

# 自定义模块，用于提取 GRU 的最后一个时间步的输出
class extract_tensor(nn.Module):
    def forward(self, x):
        tensor, _ = x
        return tensor[:, -1, :]  # 提取最后一个时间步的输出

# 构建模型
model = nn.Sequential(
    nn.GRU(features_size, hiddenSize, num_layers=2, batch_first=True, dropout=0.1),
    nn.Sequential(
        extract_tensor(),
        nn.Linear(hiddenSize, int(hiddenSize / 2)),  # 隐藏层大小减半
        nn.Linear(int(hiddenSize / 2), 1),          # 输出层
    )
)

# 打印模型结构
print(model)
```

---

## **4. 定义损失函数和优化器**

我们将使用 `GaussianNLLLoss` 作为损失函数，`RMSprop` 作为优化器。

### **代码实现**
```python
from torch import optim

# 定义损失函数
loss_function = nn.GaussianNLLLoss()

# 定义优化器
optimizer = optim.RMSprop(model.parameters(), lr=1e-3)
```

---

## **5. 训练模型**

在训练过程中，我们将：
1. 将模型切换到训练模式（`model.train()`）。
2. 使用 `DataLoader` 提供的批次数据进行训练。
3. 计算损失并反向传播（`loss.backward()`）。
4. 更新模型参数（`optimizer.step()`）。

### **代码实现**
```python
from tqdm import tqdm
import torch

# 定义训练参数
NUM_EPOCHS = 500
dev = 'cuda' if torch.cuda.is_available() else 'cpu'  # 检查是否有 GPU

# 将模型切换到训练模式
model.train()

# 将模型移动到设备（GPU 或 CPU）
model.to(dev)

# 开始训练
for epoch in range(NUM_EPOCHS):
    loop = tqdm(train_loader, position=0, leave=True)  # 进度条
    running_loss = 0.0

    for (batch, labels) in loop:
        # 清空梯度
        optimizer.zero_grad()

        # 将数据移动到设备
        batch, labels = batch.to(dev), labels.to(dev)

        # 前向传播
        output = model(batch)

        # 计算损失
        loss = loss_function(output, labels, torch.ones(output.shape).to(dev))

        # 反向传播
        loss.backward()

        # 更新参数
        optimizer.step()

        # 累加损失
        running_loss += loss.item()

        # 更新进度条
        loop.set_postfix(epoch=epoch, loss=running_loss)
```

---

## **6. 可视化结果**

在训练完成后，我们可以使用测试集数据来评估模型的性能，并绘制预测值和真实值的对比图。

### **代码实现**
```python
import matplotlib.pyplot as plt

# 切换到评估模式
model.eval()

# 初始化变量
loop = tqdm(test_loader, position=0, leave=True)

# 遍历测试集
for (batch, labels) in loop:
    # 将数据移动到设备
    batch, labels = batch.to(dev), labels.to(dev)

    # 前向传播
    output = model(batch)

    # 绘制预测值和真实值
    plt.figure(figsize=(10, 6))
    plt.plot(range(0, len(output.cpu().detach())), labels.cpu().detach(), label="Target", color='blue')
    plt.plot(range(0, len(output.cpu().detach())), output.cpu().detach(), label="Output", color='orange')
    plt.legend()
    plt.title("Model Prediction vs Target")
    plt.xlabel("Sample Index")
    plt.ylabel("Normalized Price Change (%)")
    plt.show()
```

---

## **7. 总结**

### **7.1 数据分割**
- 将数据分为训练集（80%）和测试集（20%）。

### **7.2 构建 DataLoader**
- 使用 `SequenceDataset` 类将数据转换为序列格式，并构建 `DataLoader`。

### **7.3 构建 RNN 模型**
- 使用两层 GRU 和两层全连接层构建模型。

### **7.4 定义损失函数和优化器**
- 使用 `GaussianNLLLoss` 作为损失函数，`RMSprop` 作为优化器。

### **7.5 训练和可视化**
- 训练模型 500 个 epoch，并在测试集上评估模型性能。
- 绘制预测值和真实值的对比图。

通过这些步骤，我们可以构建一个基于 RNN 的模型来预测微软股票的收盘价变化百分比。如果你有任何问题或需要进一步的帮助，请随时告诉我！
