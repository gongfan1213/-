
# Exploratory Exercise: Nvidia (NVDA)
## Please apply what you have learn from the lab to predict the stock price of Nvidia (NVDA) and show me your result. You may also try to use different technical indicators and increase the number of epochs to see if it could improve the model performance.
### Instructions
### Fetch the historical stock price data of Nvidia and visulize the data
### Split the data into train and test set
### Build dataloaders and model
### Train and evaluate the model
好的！以下是基于你之前提供的代码和要求，完成对 Nvidia (NVDA) 股票价格预测的完整解决方案。我们将按照以下步骤完成作业：

---

## **1. 获取 Nvidia (NVDA) 的历史股票价格数据并可视化**

### **代码实现**
```python
import yfinance as yf
import matplotlib.pyplot as plt

# 定义时间范围
days = '2y'  # 获取过去 2 年的数据
hrsPerDay = 7  # 每天的交易小时数

# 获取 NVDA 的历史股票数据
nvda = yf.Ticker('NVDA').history(interval='1h', period=f'{days}')

# 删除无用列
nvda.drop(columns=['Dividends', 'Stock Splits'], inplace=True)

# 打印前 5 行数据
print(nvda.head())

# 可视化收盘价
plt.figure(figsize=(18, 6))
plt.plot(nvda.index, nvda['Close'], label="Close")
plt.legend()
plt.title("NVDA Closing Prices")
plt.xlabel("Date")
plt.ylabel("Price (USD)")
plt.show()
```

---

## **2. 构建技术指标**

我们将使用 `pandas_ta` 库来计算技术指标。

### **代码实现**
```python
import pandas_ta as ta

# 定义自定义策略
custom_strategy = ta.Strategy(
    name="My Custom Strategy",
    ta=[
        {"kind": "macd"},  # 移动平均线收敛/发散
        {"kind": "bbands"},  # 布林带
        {"kind": "adx"},  # 平均方向性指数
        {"kind": "atr"},  # 平均真实范围
        {"kind": "t3"},  # T3 移动平均线
        {"kind": "mfi"},  # 资金流量指数
        {"kind": "obv"},  # 平衡交易量
        {"kind": "log_return"},  # 对数收益率
        {"kind": "zscore"},  # 滚动 Z 分数
        {"kind": "qstick", "length": 7},  # Qstick 指标
    ]
)

# 应用自定义策略
nvda.ta.strategy(custom_strategy)

# 打印前 5 行数据
print(nvda.head())
```

---

## **3. 构造目标变量和标准化**

我们将目标变量设置为收盘价的变化百分比，并对数据应用 Z-score 标准化。

### **代码实现**
```python
# 定义目标变量的偏移量
target_offset = -hrsPerDay  # 每天的交易小时数

# 计算目标变量
target = ((nvda['Close'].shift(target_offset) - nvda['Close']) / nvda['Close'] * 100)

# 应用 Z-score 标准化
nvda = (nvda - nvda.mean()) / nvda.std(ddof=0)

# 将目标变量添加到数据框
nvda['Target'] = target

# 删除缺失值
nvda.dropna(inplace=True)

# 打印前 5 行数据
print(nvda.head())
```

---

## **4. 数据分割**

我们将 80% 的数据用于训练，20% 的数据用于测试。

### **代码实现**
```python
# 定义测试集的大小
testDays = int(730 * 0.2 * hrsPerDay)  # 20% 的数据作为测试集

# 划分训练集和测试集
train_df = nvda.iloc[:-testDays]  # 训练集
test_df = nvda.iloc[-testDays:]   # 测试集

# 打印训练集和测试集的大小
print(f"Training data size: {len(train_df)}")
print(f"Testing data size: {len(test_df)}")

# 可视化训练集的目标变量
plt.figure(figsize=(18, 6))
train_df['Target'].plot()
plt.title("Training Data Target Variable")
plt.xlabel("Index")
plt.ylabel("Target")
plt.show()
```

---

## **5. 构建 PyTorch 的 DataLoader**

我们将使用之前定义的 `SequenceDataset` 类来构建训练集和测试集的 `DataLoader`。

### **代码实现**
```python
import numpy as np
import torch
from torch import nn, Tensor
from torch.utils.data import Dataset, DataLoader

# 定义超参数
sequence_size = hrsPerDay * 5  # 5 天的交易数据
batch_size = 256
features_size = len(train_df.drop(['Target'], axis=1).columns)

# 自定义 SequenceDataset 类
class SequenceDataset(Dataset):
    def __init__(self, df=pd.DataFrame(), label='', sequence_size=30):
        self.df = df
        self.label = label
        self.sequence_size = sequence_size

    def __len__(self):
        return len(self.df) - self.sequence_size

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()

        seq = Tensor(np.array(self.df.drop(self.label, axis=1).iloc[idx:idx+self.sequence_size, :], dtype=float))
        label = Tensor(np.array(self.df[[self.label]].iloc[idx+self.sequence_size, :], dtype=float))

        return (seq, label)

# 构建训练集和测试集的 DataLoader
train_loader = DataLoader(SequenceDataset(train_df, label='Target', sequence_size=sequence_size), batch_size=batch_size, shuffle=True)
test_loader = DataLoader(SequenceDataset(test_df, label='Target', sequence_size=sequence_size), batch_size=batch_size, shuffle=False)

# 打印 DataLoader 的大小
print(f"Number of training batches: {len(train_loader)}")
print(f"Number of testing batches: {len(test_loader)}")
```

---

## **6. 构建 RNN 模型**

我们将使用两层 GRU 和两层全连接层构建 RNN 模型。

### **代码实现**
```python
hiddenSize = 256

# 自定义模块，用于提取 GRU 的最后一个时间步的输出
class extract_tensor(nn.Module):
    def forward(self, x):
        tensor, _ = x
        return tensor[:, -1, :]  # 提取最后一个时间步的输出

# 构建模型
model = nn.Sequential(
    nn.GRU(features_size, hiddenSize, num_layers=2, batch_first=True, dropout=0.1),
    nn.Sequential(
        extract_tensor(),
        nn.Linear(hiddenSize, int(hiddenSize / 2)),  # 隐藏层大小减半
        nn.Linear(int(hiddenSize / 2), 1),          # 输出层
    )
)

# 打印模型结构
print(model)
```

---

## **7. 定义损失函数和优化器**

我们将使用 `GaussianNLLLoss` 作为损失函数，`RMSprop` 作为优化器。

### **代码实现**
```python
from torch import optim

# 定义损失函数
loss_function = nn.GaussianNLLLoss()

# 定义优化器
optimizer = optim.RMSprop(model.parameters(), lr=1e-3)
```

---

## **8. 训练模型**

我们将训练模型 500 个 epoch。

### **代码实现**
```python
from tqdm import tqdm
import torch

# 定义训练参数
NUM_EPOCHS = 500
dev = 'cuda' if torch.cuda.is_available() else 'cpu'  # 检查是否有 GPU

# 将模型切换到训练模式
model.train()

# 将模型移动到设备（GPU 或 CPU）
model.to(dev)

# 开始训练
for epoch in range(NUM_EPOCHS):
    loop = tqdm(train_loader, position=0, leave=True)  # 进度条
    running_loss = 0.0

    for (batch, labels) in loop:
        # 清空梯度
        optimizer.zero_grad()

        # 将数据移动到设备
        batch, labels = batch.to(dev), labels.to(dev)

        # 前向传播
        output = model(batch)

        # 计算损失
        loss = loss_function(output, labels, torch.ones(output.shape).to(dev))

        # 反向传播
        loss.backward()

        # 更新参数
        optimizer.step()

        # 累加损失
        running_loss += loss.item()

        # 更新进度条
        loop.set_postfix(epoch=epoch, loss=running_loss)
```

---

## **9. 可视化结果**

在测试集上评估模型性能，并绘制预测值和真实值的对比图。

### **代码实现**
```python
# 切换到评估模式
model.eval()

# 初始化变量
loop = tqdm(test_loader, position=0, leave=True)

# 遍历测试集
for (batch, labels) in loop:
    # 将数据移动到设备
    batch, labels = batch.to(dev), labels.to(dev)

    # 前向传播
    output = model(batch)

    # 绘制预测值和真实值
    plt.figure(figsize=(10, 6))
    plt.plot(range(0, len(output.cpu().detach())), labels.cpu().detach(), label="Target", color='blue')
    plt.plot(range(0, len(output.cpu().detach())), output.cpu().detach(), label="Output", color='orange')
    plt.legend()
    plt.title("Model Prediction vs Target")
    plt.xlabel("Sample Index")
    plt.ylabel("Normalized Price Change (%)")
    plt.show()
```

---

## **10. 总结**

### **10.1 数据处理**
- 获取 Nvidia (NVDA) 的历史股票数据。
- 构建技术指标并标准化数据。

### **10.2 模型训练**
- 使用两层 GRU 和两层全连接层构建 RNN 模型。
- 使用 `GaussianNLLLoss` 和 `RMSprop` 进行训练。

### **10.3 结果可视化**
- 在测试集上评估模型性能，并绘制预测值和真实值的对比图。

通过这些步骤，我们完成了对 Nvidia 股票价格变化百分比的预测。如果你有任何问题或需要进一步的帮助，请随时告诉我！
